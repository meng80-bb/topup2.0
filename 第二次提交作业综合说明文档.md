# 第二次提交作业综合说明文档

## 文档说明

本文档详细说明了BESIII离线事件滤波器校准流程中**第二次提交作业**（步骤2.1-2.5）的目的、意义、技术实现和物理背景。

**目标读者：** 新用户、需要了解项目背景的开发者、iFlow CLI参考文档

**相关文件：**
- 步骤2.1：`step2_1_second_job_submission.py` - 第二次作业提交并检查hist文件
- 步骤2.2：`step2_2_merge_hist.py` - 合并hist文件
- 步骤2.3：`step2_3_generate_png.py` - 生成png文件
- 步骤2.4：`step2_4_check_png_files.py` - 检查png文件
- 步骤2.5：`step2_5_merge_images.py` - 合并图片并下载
- 操作手册：`A-topup操作.docx`
- 论文：`OfflineEventFilter_rdtm2022.pdf`

---

## 一、第二次提交作业概述

### 什么是第二次提交作业？

第二次提交作业是BESIII离线事件滤波器校准流程的**第二步**，其核心任务是读取第一次提交作业生成的ROOT文件（包含IST和ETS时间戳），分析MDC和EMC探测器响应与事件-注入时间差（ΔT）的关系，生成histogram文件，为后续的背景峰值识别和滤波窗口参数确定提供数据基础。

### 在整个流程中的位置

第二次提交作业对应论文图5所示的离线数据处理流程中的关键环节：

```
第一次提交作业（提取IST和ETS）
    ↓
InjSigTime_00{run}_720.root
    ↓
[第二次提交作业]
    ↓
读取ROOT文件，分析MDC/EMC响应
    ↓
生成histogram文件（hist*.root）
    ↓
合并hist文件
    ↓
生成检查图片（check*.png）
    ↓
分析 ΔT vs 探测器响应关系
    ↓
识别背景峰值
    ↓
确定滤波窗口参数
```

这是从"时间信息提取"到"物理响应分析"的关键过渡步骤。

### 与第一次提交作业的区别

| 对比项 | 第一次提交作业 | 第二次提交作业 |
|-------|--------------|--------------|
| **输入数据** | 原始数据（*.raw文件） | 第一次提交的ROOT文件（InjSigTime文件）和interval.txt |
| **输出文件** | InjSigTime_00{run}_720.root、Interval文件 | hist*.root（histogram文件）、check*.png（检查图片） |
| **核心算法** | GetRawETS、GetTIntervalAlg、ResetEtsAlg | ResetEtsAlg、OfflineEvtFilterCalibAlg |
| **物理意义** | 提取时间戳（IST和ETS）、计算ΔT | 分析探测器响应与ΔT的关系 |
| **后续用途** | 计算ΔT = ETS - IST | 识别背景峰值，确定滤波窗口 |
| **依赖数据** | interval.txt（注入间隔） | InjSigTime文件、interval.txt |

### 步骤2的子步骤关系

步骤2包含5个子步骤，形成一个完整的数据处理流程：

```
步骤2.1：第二次作业提交（核心）
    ↓
步骤2.2：合并hist文件
    ↓
步骤2.3：生成png文件
    ↓
步骤2.4：检查png文件
    ↓
步骤2.5：合并图片并下载
```

**说明：**
- **步骤2.1**是核心，负责提交作业并生成hist文件
- **步骤2.2-2.5**是为了服务第二次提交作业，确保数据质量和可追溯性
- 所有步骤共同构成一个完整的数据处理和质量控制流程

---

## 二、第二次提交作业的物理背景

### 研究背景：BEPCII顶部注入（Top-up Injection）

**BEPCII于2019年底实现了顶部注入（top-up injection）：**
- 时间平均积分亮度提高了约30%
- 但频繁的束流注入在数据采集期间造成了明显的注入背景
- 这些背景严重影响了数据质量和物理结果的可靠性

### 核心问题：注入背景污染

**注入背景特征：**

1. **MDC（主漂移室）响应：**
   - 暗电流在注入期间增加约2倍
   - MDC几乎完全被占满，导致径迹重建困难
   - 对束流相关背景最敏感（最靠近束流管）
   - 论文图4a显示：在ΔT很小时，MDC占用率可达60%以上（4000+ hits）

2. **EMC（电磁量能器）响应：**
   - 总能量沉积可达1000 GeV以上
   - 远高于质心对撞能量（约2.0 GeV）
   - 对束流相关背景也很敏感
   - 论文图4b显示：在ΔT很小时，EMC能量沉积可达200 GeV以上

**在线触发屏蔽（Online Trigger Veto）的局限性：**
- 每次注入时，加速器系统向触发系统发送注入信号
- 接收到注入信号时间戳（IST）后，激活触发屏蔽窗口
- 屏蔽窗口内的事件被拒绝
- **问题：**由于束流不稳定性，某些严重污染的时期无法被有效屏蔽

### 解决方案：离线事件滤波器（Offline Event Filter）

**离线事件滤波器的作用：**
1. **背景峰值识别：** 基于MDC和EMC的响应识别严重背景污染时期
2. **时间差计算：** 计算 ΔT = ETS - IST（事件相对于注入的时间）
3. **滤波窗口确定：** 使用MDC和EMC的平均占用率和总能量沉积分布确定滤波窗口
4. **事件过滤：** 在事件重建前，离线事件滤波器算法访问数据库，决定保留或跳过每个事件

**应用效果：**
- 有效去除被注入背景污染的数据
- 显著改善数据质量
- 保持最佳数据采集效率
- 有助于避免蒙特卡罗模拟与数据之间的不一致性

### ΔT的物理意义

根据论文第4节，ΔT = ETS - IST 表示事件相对于最近一次注入的时间差：
- **ΔT > 0**：事件发生在注入之后
- **ΔT ≈ 0**：事件发生在注入时刻（严重污染）
- **ΔT < 0**：事件发生在注入之前（不受影响）

论文图4显示，在ΔT很小（0-10ms）时，MDC和EMC响应出现明显的峰值，表示注入期间的严重背景污染。

---

## 三、第二次提交作业的核心目标

### 1. 读取第一次提交的ROOT文件

**读取InjSigTime_00{run}_720.root文件：**

- 该文件包含第一次提交作业提取的IST（注入信号时间戳）和ETS（事件时间戳）
- 通过`CalibRootCnvSvc.InjSigTimeRootfile`参数指定
- 为后续分析提供时间基准数据

### 2. 读取interval.txt文件

**读取注入间隔信息：**

- 从`InjSigTimeCal/interval.txt`文件读取每个run的注入间隔
- 支持多种注入间隔值（60ms、20ms、150ms）
- 根据interval值动态调整ResetEtsAlg.InjSigInterval参数

**interval值转换规则：**
```bash
if [[ ${interval} == 15000000 ]]; then
    interval=60
fi
```
- 当interval值为15000000微秒（150ms）时，转换为60ms（标准topup模式）
- 其他值（如60、20）保持不变

### 3. 分析探测器响应

**分析MDC和EMC响应：**

- 使用ResetEtsAlg和OfflineEvtFilterCalibAlg算法
- 统计MDC响应（nhit_TQ_total_mdc）与ΔT的关系
- 统计EMC响应（etot_all_emc）与ΔT的关系
- 生成histogram文件记录这些分布

### 4. 生成histogram文件

**hist文件的结构：**

根据drawcheck.c脚本，hist文件包含：
- **TTree对象**：名为"event"，存储所有事件的完整信息
- **关键变量**：
  - `evt`：事件编号
  - `ets1`：事件时间戳
  - `ets2_pre`：前一次注入时间戳
  - `nhit_TQ_total_mdc`：MDC总命中数
  - `etot_all_emc`：EMC总能量沉积
  - `run`：运行编号
  - `flag_pre`：前置事件标记
  - `trigChannel_9`：触发通道状态

**ΔT的计算：**
```cpp
ΔT = (ets1 - ets2_pre) / 2000  // 单位：毫秒
```

### 5. 为后续步骤提供数据基础

**后续步骤依赖：**
- **步骤2.2**：合并hist文件（使用hadd命令）
- **步骤2.3**：生成检查图片（使用ROOT画图）
- **步骤2.4**：检查png文件完整性
- **步骤2.5**：合并图片为PDF并下载
- **步骤3-6（滤波器校准）**：基于hist数据分析MDC/EMC响应，确定滤波窗口参数

---

## 四、genJob.sh脚本详解

### 脚本功能

`genJob.sh` 脚本是第二次提交作业的核心，负责：
1. 遍历数据目录中的所有run文件
2. 为每个run创建多个作业配置文件（根据raw文件数量）
3. 读取InjSigTimeCal/interval.txt获取注入间隔
4. 根据interval值动态调整作业参数
5. 创建mergeHist.sh脚本用于合并hist文件
6. 使用BOSS框架提交作业到计算集群

### 脚本内容详解

```bash
#!/bin/bash
#-----------------------------------------------------
# 
#-----------------------------------------------------

if [ $# -lt 1 ]; then
  echo "generate job. Usage: $0 date(eg. 110311)"
  exit
fi

date=$1
pwdir=`pwd`
tempFile=${pwdir}/temp.txt
dataPath=/bes3fs/offline/data/cal/round${ROUND_NUMBER}/${date}  #=====modify
mergeFile=mergeHist.sh
jobID=0
nfile=0

# 检查日期目录是否已存在
if [ -e $1 ]; then
    echo "ERROR: ${1} exists"
    exit
fi

# 创建日期目录
mkdir $1
cd $1

# 创建mergeHist.sh脚本
touch ${mergeFile}
chmod +x ${mergeFile}

# 遍历数据目录中的所有run文件
#for file in `/bin/ls ${dataPath}/run_0073318_*raw`;
for file in `/bin/ls ${dataPath}/*.raw`;
do
  fileName=`echo $file | sed 's/.*\///g'`
  CurRun=${fileName:6:5} #substring begin with 6th , length 5
 # echo " ${date}  Run  ${CurRun} "

  # 检查是否为新的run
  if [ ! -e ${CurRun} ]; then
      mkdir ${CurRun}
      totalnum=`/bin/ls ${dataPath}/*_00${CurRun}_* |wc -l`
      jobID=0
      # 添加hist合并命令到mergeHist.sh
      echo "hadd  hist${CurRun}.root  ${CurRun}/*root  ">>"${mergeFile}"
  fi
  
  cd ${CurRun}

  # 读取interval.txt获取注入间隔
  calJob=rec${CurRun}_${jobID}
  cp $tempFile $calJob

  # 根据interval值调整注入间隔
  cat ${pwdir}/InjSigTimeCal/interval.txt | awk '{print $1,$2}' |while read run interval 
  do
  if [[ ${CurRun} == ${run} ]]; then
  if [[ ${interval} == 15000000 ]]; then
  interval=60
  fi
  sed -i  's|INTERVAL|'"${interval}"'|g' $calJob
  fi
  done

  # 替换作业模板中的占位符
  sed -i  's|RUNNO|'"${CurRun}"'|g'      $calJob
  sed -i  's|ID|'"${jobID}"'|g'          $calJob
  sed -i  's|INPUTFILE|'\"${file}\"'|g'  $calJob
  chmod +x $calJob

  # 增加作业ID
  jobID=`expr $jobID + 1`
   
  echo  ${date} "Run" ${CurRun}  $totalnum  $jobID   
   
  # 当所有作业创建完成时，提交该run的所有作业
  if [ $totalnum  -eq  $jobID ]; then
    if [ $totalnum -eq 1 ] 
    then
    boss.condor -g offlinerun  rec${CurRun}_0
    else
    boss.condor -g offlinerun  -n $totalnum rec${CurRun}'%{ProcId}'
    fi
  sleep 2
  fi
   
  cd ..
  nfile=`expr $nfile + 1`

done
 
 echo " Total = $nfile files"

 # 完成mergeHist.sh脚本
  echo " sleep 2 "                 >> "${mergeFile}"
  echo " rm */hist*_*.root -f "    >> "${mergeFile}"
  echo " du -sh * "                >> "${mergeFile}"
  echo " ls */*core* "             >> "${mergeFile}"  
  echo " mv  hist*.root ../hist "  >> "${mergeFile}"
  echo "DONE"
```

### 关键步骤说明

1. **数据路径解析：**
   - 从文件名中提取run编号（如run_0085383_XXX → 85383）
   - 每个run可能有多个raw文件（不同物理过程）

2. **interval读取和转换：**
   ```bash
   cat ${pwdir}/InjSigTimeCal/interval.txt | awk '{print $1,$2}' |while read run interval 
   do
   if [[ ${CurRun} == ${run} ]]; then
   if [[ ${interval} == 15000000 ]]; then
   interval=60
   fi
   sed -i  's|INTERVAL|'"${interval}"'|g' $calJob
   fi
   done
   ```
   - 读取interval.txt文件
   - 匹配当前run编号
   - 如果interval为15000000（150ms），转换为60（标准topup模式）
   - 替换作业模板中的INTERVAL占位符

3. **作业配置文件生成：**
   - 使用temp.txt模板
   - 替换RUNNO占位符为实际run编号
   - 替换INTERVAL占位符为注入间隔
   - 替换INPUTFILE占位符为当前raw文件路径

4. **mergeHist.sh脚本创建：**
   ```bash
   echo "hadd  hist${CurRun}.root  ${CurRun}/*root  ">>"${mergeFile}"
   ```
   - 为每个run添加hist合并命令
   - 使用hadd工具合并该run的所有hist文件

5. **作业提交：**
   - 使用BOSS框架的condor系统
   - 如果只有一个raw文件：提交单个作业`rec{run}_0`
   - 如果有多个raw文件：提交数组作业`rec{run}'%{ProcId}'`
   - 作业在计算集群上并行执行

6. **mergeHist.sh脚本完成：**
   ```bash
   echo " sleep 2 "                 >> "${mergeFile}"
   echo " rm */hist*_*.root -f "    >> "${mergeFile}"
   echo " du -sh * "                >> "${mergeFile}"
   echo " ls */*core* "             >> "${mergeFile}"  
   echo " mv  hist*.root ../hist "  >> "${mergeFile}"
   ```
   - 等待2秒
   - 删除中间hist文件（hist*_*.root）
   - 显示文件大小
   - 检查core文件
   - 移动合并后的hist文件到../hist目录

---

## 五、temp.txt作业模板详解

### 模板功能

`temp.txt` 是BOSS框架的作业配置模板，定义了作业执行的算法、参数和输入输出。

### 模板内容详解

```python
//input data
#include "$RAWDATACNVROOT/share/ReadRawDatajobOptions_dataValid.txt"
#include "$RESETETSALGROOT/share/jobOptions_ResetEtsAlg.txt"
#include "$TRIGMAKERALGROOT/share/jobOptions_TrigMakerAlg.txt"
#include "$OFFLINEEVENTLOOPMGRROOT/share/OfflineEventLoopMgr_Option.txt"
#include "$CALIBSVCROOT/share/job-CalibData.txt"
#include "$MAGNETICFIELDROOT/share/MagneticField.txt"

//configure for calibration constants
#include "$MDCUTILITYSVCROOT/share/jobOptions_MdcUtilitySvc.txt"
#include "$MDCCALIBFUNSVCROOT/share/job_MdcCalibFunSvc.txt"
#include "$CALIBSVCROOT/share/calibConfig_rec_data.txt"
#include "$OFFLINEEVTFILTERCALIBALGROOT/share/jobOptions_OfflineEvtFilterCalibAlg.txt"

ResetEtsAlg.dump = false;

ResetEtsAlg.dump = false;
ResetEtsAlg.ReadInjSigTimeFromDB = true;
CalibDataSvc.InjSigTime_CalibStorageType=5;
CalibRootCnvSvc.InjSigTimerootfile="/besfs5/groups/cal/topup/round${ROUND_NUMBER}/DataValid/InjSigTimeCal/calibConst/InjSigTime_00RUNNO_720.root";

ResetEtsAlg.ReadInjSigIntervalFromDB = false;
ResetEtsAlg.InjSigInterval = INTERVAL;

OfflineEvtFilterCalibAlg.dump = false;
OfflineEvtFilterCalibAlg.ReadInjSigIntervalFromDB = false;
OfflineEvtFilterCalibAlg.InjSigInterval = INTERVAL;

RawDataInputSvc.InputFiles={
INPUTFILE
};

//Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) 
MessageSvc.OutputLevel = 5; 
ApplicationMgr.EvtMax = -1;

ApplicationMgr.HistogramPersistency = "ROOT";
NTupleSvc.Output = {
   "FILE1 DATAFILE='histRUNNO_ID.root' OPT='NEW' TYP='ROOT'"
};
```

### 关键组件说明

#### 1. 包含的头文件

```python
#include "$RAWDATACNVROOT/share/ReadRawDatajobOptions_dataValid.txt"
```
- 原始数据转换服务配置
- 定义如何读取raw格式的数据文件

```python
#include "$RESETETSALGROOT/share/jobOptions_ResetEtsAlg.txt"
```
- ResetEtsAlg算法配置
- 定义如何重置ETS并从InjSigTime文件读取

```python
#include "$OFFLINEEVTFILTERCALIBALGROOT/share/jobOptions_OfflineEvtFilterCalibAlg.txt"
```
- 离线事件滤波器校准算法配置
- 定义如何分析MDC/EMC响应

#### 2. ResetEtsAlg算法

```python
ResetEtsAlg.dump = false;
ResetEtsAlg.ReadInjSigTimeFromDB = true;
CalibDataSvc.InjSigTime_CalibStorageType=5;
CalibRootCnvSvc.InjSigTimerootfile="/besfs5/groups/cal/topup/round${ROUND_NUMBER}/DataValid/InjSigTimeCal/calibConst/InjSigTime_00RUNNO_720.root";

ResetEtsAlg.ReadInjSigIntervalFromDB = false;
ResetEtsAlg.InjSigInterval = INTERVAL;
```

**功能：**
- 从InjSigTime文件读取IST和ETS
- 使用interval.txt中读取的注入间隔
- 生成histogram数据

**参数说明：**
- `ReadInjSigTimeFromDB`：从数据库读取IST（true表示读取）
- `InjSigTimerootfile`：IST文件路径（第一次提交生成的）
- `ReadInjSigIntervalFromDB`：从数据库读取interval（false表示不从数据库读取）
- `InjSigInterval`：注入间隔（从interval.txt读取并动态调整）

**与第一次提交的区别：**
- 第一次提交：`ReadFromDB = false`，直接从数据文件提取IST
- 第二次提交：`ReadInjSigTimeFromDB = true`，从第一次提交的ROOT文件读取IST

#### 3. OfflineEvtFilterCalibAlg算法

```python
OfflineEvtFilterCalibAlg.dump = false;
OfflineEvtFilterCalibAlg.ReadInjSigIntervalFromDB = false;
OfflineEvtFilterCalibAlg.InjSigInterval = INTERVAL;
```

**功能：**
- 分析MDC和EMC响应
- 生成用于滤波器校准的histogram
- 为后续步骤提供数据基础

#### 4. 输出配置

```python
ApplicationMgr.HistogramPersistency = "ROOT";
NTupleSvc.Output = {
   "FILE1 DATAFILE='histRUNNO_ID.root' OPT='NEW' TYP='ROOT'"
};
```

**输出文件：**
- `hist{run}_{jobID}.root`：每个作业的histogram文件
- 包含MDC和EMC响应的各种分布

---

## 六、mergeHist.sh脚本详解

### 脚本生成过程

mergeHist.sh脚本由genJob.sh自动生成，内容如下：

```bash
sleep 2
rm */hist*_*.root -f
du -sh *
ls */*core*
mv hist*.root ../hist
```

### 脚本功能说明

1. **sleep 2**：等待2秒，确保所有作业完成
2. **rm */hist*_*.root -f**：删除中间hist文件（hist*_*.root）
3. **du -sh ***：显示每个run目录的大小
4. **ls */*core***：检查是否有core文件（崩溃标志）
5. **mv hist*.root ../hist**：移动合并后的hist文件到../hist目录

### hist合并命令

在genJob.sh中为每个run添加的hist合并命令：

```bash
hadd hist${CurRun}.root  ${CurRun}/*root
```

**示例：**
```bash
hadd hist85383.root  85383/hist85383_0.root 85383/hist85383_1.root 85383/hist85383_2.root 85383/hist85383_3.root 85383/hist85383_4.root
```

**输出：**
- `hist85383.root`：合并后的hist文件
- 包含该run所有作业的histogram数据

---

## 七、输出文件详解

### 1. hist{run}.root - Histogram文件

**格式：** ROOT文件

**内容：**
- **TTree对象**：名为"event"，存储所有事件的完整信息
- **关键变量**：
  - `evt`：事件编号
  - `ets1`：事件时间戳
  - `ets2_pre`：前一次注入时间戳
  - `nhit_TQ_total_mdc`：MDC总命中数
  - `etot_all_emc`：EMC总能量沉积
  - `run`：运行编号
  - `flag_pre`：前置事件标记
  - `trigChannel_9`：触发通道状态

**物理意义：**
- `nhit_TQ_total_mdc`：MDC命中数，用于识别注入背景（论文图4a）
- `etot_all_emc`：EMC能量沉积，用于识别注入背景（论文图4b）
- `ets1`和`ets2_pre`：用于计算ΔT = (ets1 - ets2_pre) / 2000

**用途：**
- 为离线事件滤波器校准提供探测器响应数据
- 后续步骤用于分析MDC/EMC响应与ΔT的关系
- 用于生成检查图片（check*.png）

---

## 八、步骤2的子步骤详解

### 步骤2.1：第二次作业提交并检查hist文件（合并版）

**功能：**
- 确定日期参数（或从进度文件读取）
- 删除已存在的日期目录（支持自动重新提交）
- 执行genJob.sh脚本
- 定时检查hist文件是否生成完成

**关键特性：**
1. **日期参数处理：**
   - 如果传入date参数，直接使用
   - 如果未传入，从进度文件读取
   - 将日期写入进度文件

2. **自动重新提交：**
   - 如果日期目录已存在，自动删除
   - 确保作业提交时的数据是干净的

3. **定时检查：**
   - 默认等待25分钟，每30秒检查一次
   - 检查每个run号的hist文件数量
   - 对比hist文件数量和作业文件数量

4. **文件检查：**
   - 获取run号列表
   - 检查每个run的hist文件是否生成
   - 统计完成和未完成的run号

**示例运行：**

```bash
# 指定日期
python run.py --step 2.1 --date 250519

# 自定义等待时间
python run.py --step 2.1 --date 250519 --max-wait 30
```

### 步骤2.2：合并hist文件

**功能：**
- 进入日期目录
- 执行mergeHist.sh脚本
- 使用hadd工具合并hist文件

**执行的命令：**
```bash
cd {date_dir} && ./mergeHist.sh
```

**mergeHist.sh内容：**
```bash
sleep 2
rm */hist*_*.root -f
du -sh *
ls */*core*
mv hist*.root ../hist
```

**输出：**
- 合并后的hist文件：`hist{run}.root`
- 文件移动到：`../hist/`目录

**用途：**
- 将每个run的多个hist文件合并为一个
- 为后续分析提供完整的数据

### 步骤2.3：生成png文件

**功能：**
- 进入hist目录
- 执行01go.sh脚本
- 使用ROOT生成check图片

**执行的命令：**
```bash
cd {hist_dir} && ./01go.sh
```

**01go.sh脚本：**
```bash
for file in `ls *root`;
do
  CurRun=${file:4:5}  # 从文件名中提取run号（从第4位开始，长度5）
  root -q -b -l "drawcheck.c(${CurRun})"  &
  sleep 1
  echo "  Run  ${CurRun} "
done
```

**drawcheck.c脚本：**

```cpp
void drawcheck(int xx=0){
    TString name1=Form("hist%d.root",xx);
    TChain t("event");
    t.Add(name1);
    TCanvas *c=new TCanvas("c","",1800,800);
    c->Divide(3,1);  // 创建3个子图（3列1行）
    
    // 左图：事件编号 vs 时间戳
    c->cd(1);
    t.Draw("evt:ets1","ets1>80000000 && ets1<120000000");

    TLatex* a1 = new TLatex();
    a1->SetNDC(1);
    a1->SetTextSize(0.08);
    a1->DrawLatex(0.20, 0.9, Form("run%d",xx));
    
    // 中图：MDC响应 vs ΔT（论文图4a）
    c->cd(2);
    t.Draw("nhit_TQ_total_mdc:(ets1-ets2_pre)/2000","(ets1-ets2_pre)/2000>0 && (ets1-ets2_pre)/2000<60 && flag_pre!=21 && trigChannel_9==0 && ets1>1600000000 && ets1<2000000000");

    // 右图：run号 vs 事件编号（EMC高能事件）
    c->cd(3);
    t.Draw("run:evt","etot_all_emc>200000&&(ets1-ets2_pre)/2000>0&&(ets1-ets2_pre)/2000<60 && flag_pre!=21 && trigChannel_9==0");
    c->cd();

    c->SaveAs(Form("check%d.png",xx));
}
```

**三个子图的说明：**

#### 左图：事件编号 vs 时间戳
```cpp
t.Draw("evt:ets1","ets1>80000000 && ets1<120000000");
```
- **Y轴**：evt（事件编号）
- **X轴**：ets1（事件时间戳）
- **筛选**：时间戳在80M-120M范围内
- **用途**：验证数据完整性和连续性

#### 中图：MDC响应 vs ΔT（论文图4a）
```cpp
t.Draw("nhit_TQ_total_mdc:(ets1-ets2_pre)/2000",
    "(ets1-ets2_pre)/2000>0 && (ets1-ets2_pre)/2000<60 && flag_pre!=21 && trigChannel_9==0 && ets1>1600000000 && ets1<2000000000");
```
- **Y轴**：nhit_TQ_total_mdc（MDC总命中数）
- **X轴**：(ets1-ets2_pre)/2000（ΔT，单位：毫秒）
- **筛选条件**：
  - ΔT在0-60ms范围内
  - flag_pre != 21（排除某些标记事件）
  - trigChannel_9 == 0（触发通道条件）
  - ets1在特定时间窗口内（1600M-2000M）
- **用途**：识别MDC背景峰值，确定滤波窗口
- **对应论文**：图4a
- **预期行为**：
  - 在ΔT很小（0-10ms）时出现明显的峰值
  - 峰值表示注入期间MDC受到严重背景污染
  - 峰值可能达到60%以上的占用率（4000+ hits）

#### 右图：run号 vs 事件编号（EMC高能事件）
```cpp
t.Draw("run:evt","etot_all_emc>200000&&(ets1-ets2_pre)/2000>0&&(ets1-ets2_pre)/2000<60 && flag_pre!=21 && trigChannel_9==0");
```
- **Y轴**：evt（事件编号）
- **X轴**：run（运行编号）
- **筛选**：EMC总能量 > 200000，且ΔT在0-60ms范围内
- **用途**：识别高能EMC事件，用于异常事例分析

**输出：**
- check{run}.png：包含三个子图的检查图片
- 每个run生成一个check图片

### 步骤2.4：检查png文件

**功能：**
- 定时检查hist目录下是否每个hist文件都生成了对应的check图片

**执行的命令：**
```bash
# 获取hist文件列表
cd {hist_dir} && ls hist*.root

# 获取check图片列表
cd {hist_dir} && ls check*.png
```

**说明：**
- 对比hist文件数量和check图片数量
- 确保所有hist文件都已转换为check图片

**关键特性：**
- 默认最大等待25分钟
- 每30秒检查一次
- 实时显示进度

**返回内容：**
- 总hist文件数
- 总check图片数
- 耗时

### 步骤2.5：合并hist图片并下载

**功能：**
- 进入hist目录，进入SL6容器
- 使用ImageMagick的convert命令将所有check图片合并为PDF
- 通过SFTP下载PDF文件到本地

**执行的命令：**
```bash
cd {hist_dir} && /cvmfs/container.ihep.ac.cn/bin/hep_container shell SL6 << 'EOF'
convert *.png mergedd_Hist.pdf
exit
EOF
```

**技术细节：**

1. **容器环境：**
   - 使用`/cvmfs/container.ihep.ac.cn/bin/hep_container shell SL6`进入SL6容器
   - 容器中预装了ImageMagick工具

2. **图片合并：**
   - 使用`convert *.png mergedd_Hist.pdf`命令
   - 按文件名顺序合并所有check图片
   - 输出文件名为`mergedd_Hist.pdf`

3. **文件下载：**
   - 使用SFTP协议下载PDF文件
   - 保存到本地`downloads/`目录
   - 文件名格式：`mergedd_Hist_{date}.pdf`

**下载路径：**
- 远程：`{hist_dir}/mergedd_Hist.pdf`
- 本地：`{LOCAL_DOWNLOAD_DIR}/mergedd_Hist_{date}.pdf`
- 默认本地目录：`C:\Users\孟皇薪\Desktop\topup\downloads\`

**用途：**
- 方便人工审核所有run的hist检查图片
- 可以快速浏览数据质量
- 便于存档和共享

---

## 九、第二次提交作业在离线事件滤波器中的作用

### 数据流程图

```
第一次提交作业的输出
    ↓
InjSigTime_00{run}_720.root（包含IST和ETS）
interval.txt（包含注入间隔）
    ↓
[步骤2.1：第二次作业提交]
    ├─ 读取InjSigTime文件
    ├─ 读取interval.txt
    ├─ 根据interval值调整注入间隔
    ├─ 运行 ResetEtsAlg 算法
    │  ├─ 从InjSigTime文件读取IST
    │  ├─ 计算ΔT = ETS - IST
    │  └─ 生成histogram数据
    └─ 运行 OfflineEvtFilterCalibAlg 算法
       ├─ 分析MDC响应（nhit_TQ_total_mdc）
       ├─ 分析EMC响应（etot_all_emc）
       └─ 保存到 hist{run}_{jobID}.root
    ↓
多个hist文件（hist{run}_{jobID}.root）
    ↓
[步骤2.2：合并hist文件]
    ├─ 执行mergeHist.sh脚本
    ├─ 使用hadd合并hist文件
    └─ 移动到hist目录
    ↓
合并后的hist文件（hist{run}.root）
    ↓
[步骤2.3：生成png文件]
    ├─ 执行01go.sh脚本
    ├─ 使用ROOT生成check图片
    └─ 生成check{run}.png
    ↓
check图片（check{run}.png）
    ↓
[步骤2.4：检查png文件]
    └─ 确认所有check图片都已生成
    ↓
[步骤2.5：合并图片并下载]
    ├─ 合并check图片为PDF
    └─ 下载到本地
    ↓
mergedd_Hist_{date}.pdf
    ↓
[步骤3-6：滤波器校准]
    ├─ 分析MDC/EMC响应 vs ΔT
    ├─ 识别背景峰值（论文图4a、4b）
    ├─ 确定滤波窗口参数（论文图4c、4d）
    └─ 保存到校准数据库
    ↓
[步骤7：提交数据库]
    └─ 将滤波器参数保存到数据库
    ↓
在事件重建时应用滤波器
```

### 物理意义

通过准确分析MDC和EMC响应与事件-注入时间差的关系，第二次提交作业为：
- 识别注入背景污染事件
- 确定最优滤波窗口
- 提高数据质量
- 保证物理结果的可靠性

提供了关键的探测器响应数据。

### 与论文的对应

第二次提交作业对应论文中图5的 **"Offline Event Filter Calibration"** 框，是实现离线事件滤波器的关键步骤。

**对应关系：**

| 论文概念 | 第二次提交作业实现 |
|---------|-----------------|
| MDC响应 vs ΔT（图4a） | hist文件中的nhit_TQ_total_mdc vs ΔT |
| EMC响应 vs ΔT（图4b） | hist文件中的etot_all_emc vs ΔT |
| 背景峰值识别 | 分析check{run}.png的中图 |
| 滤波窗口确定 | 基于histogram数据分析峰值特征 |

---

## 十、示例：run85383的完整流程

### 1. 第一次提交的输出文件

**InjSigTime_0085383_720.root：**
- 包含run85383的IST和ETS数据
- 保存位置：`InjSigTimeCal/calibConst/`

**Interval_run85383.txt：**
```
                    85383
  interval_before_sorting                 15000000
         interval_From_DB                 15000000
   interval_after_sorting                 15000000
```

**interval.txt：**
```
85383 15000000
```

### 2. 第二次提交的作业配置文件

**rec85383_0.txt：**
```python
#include "$RAWDATACNVROOT/share/ReadRawDatajobOptions_dataValid.txt"
#include "$RESETETSALGROOT/share/jobOptions_ResetEtsAlg.txt"
// ... 其他包含 ...

ResetEtsAlg.dump = false;
ResetEtsAlg.ReadInjSigTimeFromDB = true;
CalibDataSvc.InjSigTime_CalibStorageType=5;
CalibRootCnvSvc.InjSigTimerootfile="/besfs5/groups/cal/topup/round18/DataValid/InjSigTimeCal/calibConst/InjSigTime_0085383_720.root";

ResetEtsAlg.ReadInjSigIntervalFromDB = false;
ResetEtsAlg.InjSigInterval = 60;  // 从15000000转换为60

OfflineEvtFilterCalibAlg.dump = false;
OfflineEvtFilterCalibAlg.ReadInjSigIntervalFromDB = false;
OfflineEvtFilterCalibAlg.InjSigInterval = 60;

RawDataInputSvc.InputFiles={
"/bes3fs/offline/data/cal/round18/250519/run_0085383_BBhabha_file001_SFO-1.raw"
};

MessageSvc.OutputLevel = 5; 
ApplicationMgr.EvtMax = -1;

ApplicationMgr.HistogramPersistency = "ROOT";
NTupleSvc.Output = {
   "FILE1 DATAFILE='hist85383_0.root' OPT='NEW' TYP='ROOT'"
};
```

### 3. 作业配置文件（rec85383_0.txt）

**完整的作业配置文件：**

```python
//input data
#include "$RAWDATACNVROOT/share/ReadRawDatajobOptions_dataValid.txt"
#include "$RESETETSALGROOT/share/jobOptions_ResetEtsAlg.txt"
#include "$TRIGMAKERALGROOT/share/jobOptions_TrigMakerAlg.txt"
#include "$OFFLINEEVENTLOOPMGRROOT/share/OfflineEventLoopMgr_Option.txt"
#include "$CALIBSVCROOT/share/job-CalibData.txt"
#include "$MAGNETICFIELDROOT/share/MagneticField.txt"

//configure for calibration constants
#include "$MDCUTILITYSVCROOT/share/jobOptions_MdcUtilitySvc.txt"
#include "$MDCCALIBFUNSVCROOT/share/job_MdcCalibFunSvc.txt"
#include "$CALIBSVCROOT/share/calibConfig_rec_data.txt"
#include "$OFFLINEEVTFILTERCALIBALGROOT/share/jobOptions_OfflineEvtFilterCalibAlg.txt"

ResetEtsAlg.dump = false;

ResetEtsAlg.dump = false;
ResetEtsAlg.ReadInjSigTimeFromDB = true;
CalibDataSvc.InjSigTime_CalibStorageType=5;
CalibRootCnvSvc.InjSigTimerootfile="/besfs5/groups/cal/topup/round${ROUND_NUMBER}/DataValid/InjSigTimeCal/calibConst/InjSigTime_0085383_720.root";

ResetEtsAlg.ReadInjSigIntervalFromDB = false;
ResetEtsAlg.InjSigInterval = 60;

OfflineEvtFilterCalibAlg.dump = false;
OfflineEvtFilterCalibAlg.ReadInjSigIntervalFromDB = false;
OfflineEvtFilterCalibAlg.InjSigInterval = 60;

RawDataInputSvc.InputFiles={
"/bes3fs/offline/data/cal/round18/250519/run_0085383_BBhabha_file001_SFO-1.raw"
};

//Set output level threshold (2=DEBUG, 3=INFO, 4=WARNING, 5=ERROR, 6=FATAL ) 
MessageSvc.OutputLevel = 5; 
ApplicationMgr.EvtMax = -1;

ApplicationMgr.HistogramPersistency = "ROOT";
NTupleSvc.Output = {
   "FILE1 DATAFILE='hist85383_0.root' OPT='NEW' TYP='ROOT'"
};
```

**关键配置说明：**

1. **算法加载：**
   - ResetEtsAlg：重置事件时间戳，从InjSigTime文件读取IST
   - OfflineEvtFilterCalibAlg：离线事件滤波器校准算法
   - TrigMakerAlg：触发器算法

2. **IST读取配置：**
   ```python
   ResetEtsAlg.ReadInjSigTimeFromDB = true;
   CalibDataSvc.InjSigTime_CalibStorageType=5;
   CalibRootCnvSvc.InjSigTimerootfile="/besfs5/groups/cal/topup/round${ROUND_NUMBER}/DataValid/InjSigTimeCal/calibConst/InjSigTime_0085383_720.root";
   ```
   - 从数据库读取IST（true）
   - 使用存储类型5（ROOT文件）
   - 指定IST文件路径

3. **注入间隔配置：**
   ```python
   ResetEtsAlg.ReadInjSigIntervalFromDB = false;
   ResetEtsAlg.InjSigInterval = 60;
   
   OfflineEvtFilterCalibAlg.ReadInjSigIntervalFromDB = false;
   OfflineEvtFilterCalibAlg.InjSigInterval = 60;
   ```
   - 不从数据库读取interval（false）
   - 使用interval.txt中读取的值（60ms）
   - 两个算法都使用相同的注入间隔

4. **输入文件：**
   ```python
   RawDataInputSvc.InputFiles={
   "/bes3fs/offline/data/cal/round18/250519/run_0085383_BBhabha_file001_SFO-1.raw"
   };
   ```
   - 原始数据文件路径
   - BBhabha物理过程

5. **输出配置：**
   ```python
   ApplicationMgr.HistogramPersistency = "ROOT";
   NTupleSvc.Output = {
      "FILE1 DATAFILE='hist85383_0.root' OPT='NEW' TYP='ROOT'"
   };
   ```
   - 输出格式：ROOT
   - 输出文件：hist85383_0.root

### 4. 作业执行日志（rec85383_0.bosslog）

**关键执行信息：**

**作业提交信息：**
```
Job 51952561.0 submitted at 2026-02-20 19:58:28
Sent to slot18 @cws051.ihep.ac.cn
```
- 作业ID：51952561.0
- 提交时间：2026-02-20 19:58:28
- 执行节点：cws051.ihep.ac.cn slot18

**BOSS版本：**
```
BOSS version: 7.2.0
```

**成功加载的模块：**
```
Successfully loaded modules : RawDataCnv, DatabaseSvc, CgemInfoLuSvc, ResetEtsAlg, InjSigIntervalSvc, InjSigTimeSvc, TrigMakerAlg, DummyLoadOldROOT, OfflineEventLoopMgr, CalibMySQLCnv, CalibROOTCnv, CalibDataSvc, CalibTreeCnv, MagneticField, MdcUtilitySvc, MdcGeomSvc, MdcCalibFunSvc, OfflineEvtFilterCalibAlg, EmcRecGeoSvc, EmcCalibConstSvc
```

**配置文件读取：**
```
JobOptionsSvc        INFO # (15,1): ResetEtsAlg.dump = 0
JobOptionsSvc        INFO # (17,1): ResetEtsAlg.dump = 0
JobOptionsSvc        INFO # (18,1): ResetEtsAlg.ReadInjSigTimeFromDB = 1
JobOptionsSvc        INFO # (19,1): CalibDataSvc.InjSigTime_CalibStorageType = 5
JobOptionsSvc        INFO # (20,1): CalibRootCnvSvc.InjSigTimerootfile = "/besfs5/groups/cal/topup/round${ROUND_NUMBER}/DataValid/InjSigTimeCal/calibConst/InjSigTime_0085383_720.root"
JobOptionsSvc        INFO # (22,1): ResetEtsAlg.ReadInjSigIntervalFromDB = 0
JobOptionsSvc        INFO # (23,1): ResetEtsAlg.InjSigInterval = 60
JobOptionsSvc        INFO # (25,1): OfflineEvtFilterCalibAlg.dump = 0
JobOptionsSvc        INFO # (26,1): OfflineEvtFilterCalibAlg.ReadInjSigIntervalFromDB = 0
JobOptionsSvc        INFO # (27,1): OfflineEvtFilterCalibAlg.InjSigInterval = 60
```

**数据文件读取：**
```
[RawFile] Prepare for reading: /bes3fs/offline/data/cal/round18/250519/run_0085383_BBhabha_file001_SFO-1.raw
[RawFile] Reach end of data file: /bes3fs/offline/data/cal/round18/250519/run_0085383_BBhabha_file001_SFO-1.raw
[RawFile] Congratulations. Reach end of data file list !
```

**注入间隔确认：**
```
ResetEts::execute() m_interval = 60
```
- ResetEtsAlg确认使用60ms作为注入间隔

**EMC校准数据加载：**
```
Emc runfrm,runto in getSftParVer is:85383::::1000000
 @table Emc: RunFrom is:85383 RunTo is:85955
 SftVer is 7.2.0 CalVerSft is 1 File name  is EmcCalibConstIthe85763-85952-emc.root
```
- EMC校准常量文件加载成功

**执行完成：**
```
ApplicationMgr       INFO Application Manager Stopped successfully
ApplicationMgr       INFO Application Manager Finalized successfully
ApplicationMgr       INFO Application Manager Terminated successfully
4.941u 0.495s 0:14.15 38.3%	0+0k 648+152io 325pf+0w
```
- 执行时间：14.15秒
- CPU时间：4.941秒
- 系统时间：0.495秒
- CPU使用率：38.3%

### 5. 错误信息（rec85383_0.bosserr）

**主要错误信息：**

```
Error in <TCling::LoadPCM>: ROOT PCM /cvmfs/bes3.ihep.ac.cn/bes3sw/Boss/7.2.0/Event/RootEventData/RootEventData-00-05-00/x86_64-centos7-gcc49-opt/RootEventData_rootcint_rdict.pcm file does not exist
```

**说明：**
- 这是一个ROOT PCM（Precompiled Module）文件加载错误
- PCM文件是ROOT的预编译模块文件
- 缺少该文件不会影响主要功能
- 这是ROOT系统的警告，不是致命错误

**其他PCM加载信息：**
```
Info in <TCling::LoadPCM>: In-memory ROOT PCM candidate /cvmfs/bes3.ihep.ac.cn/bes3sw/ExternalLib/lcg/LCG_84/ROOT/6.20.02/x86_64-centos7-gcc49-opt-python2.7/lib/libEG_rdict.pcm
Info in <TCling::LoadPCM>: In-memory ROOT PCM candidate /cvmfs/bes3.ihep.ac.cn/bes3sw/ExternalLib/lcg/LCG_84/ROOT/6.20.02/x86_64-centos7-gcc49-opt-python2.7/lib/libEve_rdict.pcm
...
```
- 这些是ROOT尝试加载各种PCM文件的信息
- 属于正常的系统行为

**几何加载信息：**
```
Info in <TGeoManager::TGeoManager>: Geometry BesGeo, Bes geometry created
```
- BESIII几何创建成功

**错误处理：**
- 虽然有PCM文件加载错误，但作业成功完成
- 这些错误不影响hist文件的生成
- 可以忽略这些警告

### 6. 输出文件

**hist85383_0.root、hist85383_1.root等：**
- 每个raw文件生成一个hist文件
- 包含MDC和EMC响应的histogram数据

**hist85383.root（合并后）：**
```bash
hadd hist85383.root  85383/hist85383_0.root 85383/hist85383_1.root 85383/hist85383_2.root 85383/hist85383_3.root 85383/hist85383_4.root
```
- 合并后的hist文件
- 包含该run所有作业的histogram数据

**check85383.png：**
- 包含三个子图：
  - 左图：事件编号 vs 时间戳
  - 中图：MDC响应 vs ΔT
  - 右图：run号 vs 事件编号

---

## 十一、作业执行过程详解

### 作业执行的完整流程

```
1. 作业提交
   ├─ 作业ID：51952561.0
   ├─ 提交时间：2026-02-20 19:58:28
   └─ 执行节点：cws051.ihep.ac.cn slot18

2. 初始化
   ├─ 加载BOSS 7.2.0版本
   ├─ 加载所有必需模块
   └─ 初始化服务（DatabaseSvc、MagneticField等）

3. 读取配置
   ├─ 读取作业配置文件（rec85383_0.txt）
   ├─ 读取InjSigTime文件
   ├─ 读取EMC校准数据
   └─ 读取MDC校准数据

4. 数据处理
   ├─ 打开原始数据文件
   ├─ 执行ResetEtsAlg算法
   │  ├─ 从InjSigTime文件读取IST
   │  ├─ 计算ΔT = ETS - IST
   │  └─ 使用注入间隔60ms
   └─ 执行OfflineEvtFilterCalibAlg算法
      ├─ 分析MDC响应
      └─ 分析EMC响应

5. 生成histogram
   ├─ 创建hist85383_0.root文件
   ├─ 写入TTree对象（event）
   └─ 写入histogram数据

6. 完成
   ├─ 关闭数据文件
   ├─ 保存histogram文件
   └─ 终止作业
```

### 关键时间节点

| 时间节点 | 事件 | 说明 |
|---------|------|------|
| 19:58:28 | 作业提交 | 提交到condor队列 |
| 20:16:18 | 作业开始 | 开始执行 |
| 20:16:18-20:16:19 | 初始化 | 加载模块和服务 |
| 20:16:19-20:16:20 | 读取数据 | 读取原始数据文件 |
| 20:16:20-20:30:33 | 数据处理 | 执行算法分析 |
| 20:30:33 | 完成 | 生成hist文件 |

### 资源使用情况

```
4.941u 0.495s 0:14.15 38.3%	0+0k 648+152io 325pf+0w
```

| 资源类型 | 使用量 | 说明 |
|---------|--------|------|
| CPU时间 | 4.941秒 | 用户态CPU时间 |
| 系统时间 | 0.495秒 | 内核态CPU时间 |
| 总时间 | 14.15秒 | 墙钟时间 |
| CPU使用率 | 38.3% | CPU利用率 |
| 内存 | 0+0k | 没有交换内存使用 |
| I/O读取 | 648块 | 读取块数 |
| I/O写入 | 152块 | 写入块数 |
| 缺页 | 325 | 页面错误 |

### 与第一次提交作业的对比

| 特性 | 第一次提交作业 | 第二次提交作业 |
|-----|--------------|--------------|
| **输入文件** | 原始数据（*.raw） | 原始数据（*.raw） |
| **IST来源** | 从原始数据提取 | 从InjSigTime文件读取 |
| **注入间隔** | 从数据计算（60ms） | 从interval.txt读取（60ms） |
| **输出文件** | InjSigTime_00{run}_720.root | hist{run}_{jobID}.root |
| **主要算法** | GetRawETS、GetTIntervalAlg | ResetEtsAlg、OfflineEvtFilterCalibAlg |
| **执行时间** | 约10-15分钟 | 约14分钟 |
| **内存使用** | 较高 | 中等 |

### 典型执行时间

根据日志信息，第二次提交作业的典型执行时间：

| Run编号 | Raw文件数量 | 执行时间 | 说明 |
|---------|-------------|---------|------|
| 85383 | 1 | 14.15秒 | 单个BBhabha文件 |
| 85384 | 5 | 约20-30秒 | 多个物理过程文件 |
| 85385 | 3 | 约15-20秒 | 中等数量文件 |

---

## 十二、常见问题和解决方法

### 问题1：hist文件生成超时

**症状：**
```
在 25 分钟内未完成所有hist文件的生成
```

**原因：**
- 计算集群负载高
- run数量多
- 网络问题

**解决方法：**
- 增加等待时间：`python run.py --step 2.1 --date 250519 --max-wait 30`
- 检查作业状态：`hep_q -u topup`
- 重新提交失败的作业

### 问题2：interval转换错误

**症状：**
```
interval值未正确转换
```

**原因：**
- interval.txt文件格式错误
- interval值不在预期范围内

**解决方法：**
- 检查interval.txt文件格式
- 确认interval值是否为15000000、60或20
- 手动调整interval.txt文件

### 问题3：check图片生成失败

**症状：**
```
check*.png文件未生成
```

**原因：**
- hist文件损坏
- ROOT画图脚本错误
- ets1范围不匹配

**解决方法：**
- 检查hist文件是否完整
- 检查drawcheck.c脚本中的筛选条件
- 调整ets1范围以匹配实际数据

### 问题4：图片合并失败

**症状：**
```
执行图片合并失败
```

**原因：**
- 容器环境问题
- ImageMagick未安装
- 磁盘空间不足

**解决方法：**
- 检查容器是否正常
- 检查ImageMagick是否可用
- 检查磁盘空间

---

## 十二、总结

### 第二次提交作业的本质

第二次提交作业是 **BESIII离线事件滤波器校准流程的第二步**，其核心任务是：

1. **读取第一次提交的ROOT文件**：获取IST和ETS时间戳数据
2. **读取interval.txt文件**：获取注入间隔信息
3. **分析探测器响应**：统计MDC和EMC响应与ΔT的关系
4. **生成histogram文件**：记录各种统计分布
5. **生成检查图片**：用于人工审核数据质量
6. **为后续滤波器校准提供数据基础**：用于背景峰值识别和滤波窗口确定

### 关键技术点

1. **genJob.sh脚本**：自动化作业生成和提交
2. **interval转换**：从15000000转换为60ms
3. **ResetEtsAlg算法**：从InjSigTime文件读取IST
4. **OfflineEvtFilterCalibAlg算法**：分析MDC/EMC响应
5. **mergeHist.sh脚本**：合并hist文件
6. **01go.sh和drawcheck.c脚本**：生成检查图片
7. **定时检查机制**：确保作业完成
8. **SFTP下载**：自动下载PDF文件

### 物理意义

通过准确分析MDC和EMC响应与事件-注入时间差的关系，第二次提交作业为：
- 识别注入背景污染事件
- 确定最优滤波窗口
- 提高数据质量
- 保证物理结果的可靠性

提供了关键的探测器响应数据基础。

### 与第一次提交作业的关系

| 特性 | 第一次提交作业 | 第二次提交作业 |
|-----|--------------|--------------|
| **数据来源** | 原始数据（*.raw） | 第一次提交的ROOT文件 |
| **时间信息** | 提取IST和ETS | 使用已提取的IST和ETS |
| **注入间隔** | 从数据计算 | 从interval.txt读取 |
| **输出** | 时间信息文件 | 探测器响应histogram |
| **目的** | 建立时间基准 | 分析探测器响应 |
| **后续用途** | 为第二次提交提供数据 | 为滤波器校准提供数据 |

---

## 附录A：相关文件路径

### 远程服务器路径

```
/besfs5/groups/cal/topup/round18/DataValid/          # 工作目录
/besfs5/groups/cal/topup/round18/DataValid/{date}/  # 日期目录
/besfs5/groups/cal/topup/round18/DataValid/hist/     # hist文件目录
/bes3fs/offline/data/cal/round18/{date}/             # 数据目录
/besfs5/groups/cal/topup/round18/DataValid/InjSigTimeCal/    # 第一次提交目录
/besfs5/groups/cal/topup/round18/DataValid/InjSigTimeCal/calibConst/  # IST文件目录
/besfs5/groups/cal/topup/round18/DataValid/InjSigTimeCal/interval.txt  # interval文件
```

### 本地路径

```
C:\Users\孟皇薪\Desktop\topup\downloads\              # 下载目录
C:\Users\孟皇薪\Desktop\topup\logs\                   # 日志目录
C:\Users\孟皇薪\Desktop\topup\.step_progress          # 进度文件
```

---

## 附录B：命令参考

### 执行步骤

```bash
# 执行单个步骤
python run.py --step 2.1 --date 250519

# 执行所有步骤（步骤1-7）
python run.py --all --date 250519

# 从断点继续
python run.py --continue

# 批量处理（total模式）
python run.py --total
```

### 查看作业状态

```bash
# 查看topup用户的作业
hep_q -u topup -g physics

# 查看所有用户的作业
hep_q -u

# 查看具体作业详情
hep_q -j <job_id>
```

### 手动操作

```bash
# 进入工作目录
cd /besfs5/groups/cal/topup/round18/DataValid

# 提交作业
./genJob.sh 250519

# 查看文件数量
ls *root | wc -l
ls *png | wc -l

# 进入hist目录
cd hist

# 查看interval.txt
cat /besfs5/groups/cal/topup/round18/DataValid/InjSigTimeCal/interval.txt

# 进入SL6容器
/cvmfs/container.ihep.ac.cn/bin/hep_container shell SL6

# 生成检查图片
./01go.sh

# 退出容器
exit

# 合并图片
convert *.png mergedd.pdf

# 查看hist文件
root -l hist85383.root
event->Draw("nhit_TQ_total_mdc:(ets1-ets2_pre)/2000")
```

---

## 附录C：术语表

| 术语 | 英文 | 含义 |
|------|------|------|
| IST | Injection Signal Time Stamp | 注入信号时间戳 |
| ETS | Event Time Stamp | 事件时间戳 |
| ΔT | Delta Time | 事件与注入的时间差 |
| MDC | Main Drift Chamber | 主漂移室 |
| EMC | Electromagnetic Calorimeter | 电磁量能器 |
| BOSS | BESIII Offline Software System | BESIII离线软件系统 |
| topup | top-up injection | 顶部注入 |
| ROOT | ROOT Data Analysis Framework | ROOT数据分析框架 |
| condor | HTCondor Job Scheduler | HTCondor作业调度系统 |
| hadd | ROOT histogram add tool | ROOT直方图合并工具 |
| ResetEtsAlg | Reset Event Time Stamp Algorithm | 重置事件时间戳算法 |
| OfflineEvtFilterCalibAlg | Offline Event Filter Calibration Algorithm | 离线事件滤波器校准算法 |

---

**文档创建时间：** 2026年2月7日
**最后更新时间：** 2026年2月20日
**基于论文：** "Suppression of top-up injection backgrounds with offline event filter in the BESIII experiment" (Radiation Detection Technology and Methods, 2022)
**基于操作手册：** A-topup操作.docx
**作者：** iFlow CLI